---
title: "COVID-19 Importation - California"
author: "Shaun Truelove"
email: "shauntruelove@jhu.edu"
date: "`r Sys.time()`"
geometry: margin=.5in
output:
  html_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}

options(scipen = 999)
knitr::opts_knit$set(root.dir = "..")
knitr::opts_chunk$set(echo = TRUE)

if(!require('knitr')) install.packages('knitr'); library(knitr)
if(!require('tidyverse')) install.packages('tidyverse'); library(tidyverse)
if(!require('gridExtra')) install.packages('gridExtra'); library(gridExtra)
if(!require('grid')) install.packages('grid'); library(grid)
if(!require('viridis')) install.packages('viridis'); library(viridis)

# Packages
# if(!require('stringr')) install.packages('stringr'); library(stringr)
# if(!require('lettercase')) install.packages('lettercase'); library(lettercase)
# if(!require('fields')) install.packages('fields'); library(fields)
# if(!require('pracma')) install.packages('pracma'); library(pracma)
# if(!require('msm')) install.packages('msm'); library(msm)
# if(!require('countrycode')) install.packages('countrycode'); library(countrycode)
# if(!require('tools')) install.packages('tools'); library(tools)
select <- dplyr::select

print(getwd())
source("../R/DataLoadUtils.r")
source("../R/BasicEpiAnalyses.r")
# source("R/DataLoadUtils.r")
# source("R/BasicEpiAnalyses.r")

```

This document details the full analysis process for estimating the COVID-19 importation risk and numbers into the U.S. from other countries. Currently this is set up for importation only into US Airports from Hubei, China. This work is an adaptation of work done for measles importation for the manuscript titled "Epidemics, Air Travel, and Elimination in a Globalized World: The Case of Measles".  

The model requires a set of epidemiological parameters (incubation period, infectious period, proportion of cases reported), which currently come from data on Chinese cases and cases that have traveled from China. Case data on cases in source locations comes from publicly reported cases. We are using a smoothing technique to make these more uniform, and have location and time-specific assumptions about what proportion of cases are currently being reported. Travel data with full trip iteneraries is required, and currently we are using data provided by the U.S. CDC obtained from OAG.

Alterations can be done in this R markdown file to explore scenarios, do sensitivity analyses, or update assumptions and data. Data changes should be done in the **DATA** block below or the sourced scripts. Parameter changes should be done in the **COVID-19 CHARACTERISTICS** section. Results tables are saved as CSV files and then used to produce the figures below.
    
The current analysis includes estimates of importation into US airports from Hubei, China up to January 25, 2020. On January 23, Hubei was put under quarantine, after which flights from Hubei were cancelled, though we allow a couple extra days for travel due to time to travel and layovers.

    
    
# MODEL SETUP

### Project Options

```{r projoptions, echo=TRUE}
# Analysis Options
project_name <- "usa_import"
version <- "wuhan_only"
batch <- "1st"
n_sim <- 100

end_date <- as.Date("2020-03-01")

# Create needed directories
dir.create(file.path("output",project_name), recursive = TRUE, showWarnings = FALSE)
dir.create(file.path("data",project_name), recursive = TRUE, showWarnings = FALSE)
results_dir <- file.path("figures", project_name)
dir.create(results_dir, recursive = TRUE)

```

    
        
            
# COVID-19 CHARACTERISTICS    
    
    
### Incubation period
We are assuming the incubation follows a lognormal distribution that follows estimates from Lauer et al. 2020 (mean = 5.2 days (95% CI 2.5-10.5)). Source: https://www.medrxiv.org/content/10.1101/2020.02.02.20020016v1.


```{r incub, echo=FALSE}

# Incubation
# mean: 5.2 days (95% CI 2.5-10.5) 
incub_mean_log <- log(5.2)
incub_sd_log   <- log(1.43)

samp_incub <- exp(rnorm(10000, incub_mean_log, incub_sd_log))
quantile(samp_incub, probs=c(0.025, .50,  0.975))

```

### Infectious period
We are using different infectious periods for those detected and hospitalized and those not.
These estimates are based off a combination of anecdotal evidence and estimates from SARS. This will be updated using data from COVID-19 soon.

#### Infectious period - not hospitalized
```{r infectperiod_nohosp, echo=FALSE}
inf_period_nohosp_mean <- 7  # needs revision
inf_period_nohosp_sd   <- 4

#inf_nohosp <- exp(MCMCglmm::rtnorm(10000, log(inf_period_nohosp_mean), log(inf_period_nohosp_sd), lower=0))
inf_nohosp <- (MCMCglmm::rtnorm(10000, inf_period_nohosp_mean, inf_period_nohosp_sd, lower=0))

quantile(inf_nohosp, probs=c(0.025, .5, 0.975))
print(paste0("Mean time to recovery: ", round(mean(inf_nohosp),1), " days"))
```
    
    
#### Infectious period - hospitalized (time to hospitalization)
```{r infectperiod_hosp, echo=FALSE}

inf_period_hosp_shape <- 0.46  
inf_period_hosp_scale <- 5.367

inf_hosp <- rgamma(1000, shape=inf_period_hosp_shape, scale=inf_period_hosp_scale)

quantile(inf_hosp, probs=c(0.025, .5,  0.975))
print(paste0("Mean time to hospitalization: ", round(mean(inf_hosp),1), " days"))
```

Visually, these are the distributions that we are drawing from to inform these time period:
```{r plot_params, echo=FALSE}

par(mfrow=c(1,3))

plot(density(samp_incub), type="l", main="Incubation Period", xlab="Days")

plot(density(inf_nohosp), type="l", col="blue", ylim=c(0,.3), xlim=c(0, 30), 
     main="Time to recovery", xlab="days")
plot(density(inf_hosp), type="l", col="red", ylim=c(0,.35), xlim=c(0, 30), 
        main="Time to hospitalization", xlab="days")

par(mfrow=c(1,1))

```


    
### Proportion cases reported

```{r}
p_report_source <- c(0.05, 0.25)

```
Currently the model is set up to take both time- and location-varying proportion of cases reported. For now, we are using `r p_report_source[1]*100`% reported for Hubei, and `r p_report_source[2]*100`% reported elsewhere, constant over time.  
     
### Shift in incidence date
```{r}
shift_incid_days <- -5 
```
To appropriately allign reported cases of COVID-19 in source locations with the time during which they might be traveling, we shift case reporting dates by `r shift_incid_days` days (i.e., backward). This is a crude adjustment for now that will be improved.


  
    
    
# DATA

Here we describe where we get data and do necessary formatting and cleaning of the data.

Three major sets of data are required for this importation estimation model: incidence in source locations, mobility or travel volume from source locations in to destination locations, and population of source locations. Data processing is done within separate R scripts for each. These each are setup to process and save the files in the correct formats for running the model.
**To run these source scripts within this Rmd file, make sure to change `eval=FALSE` to `eval=TRUE`. 


## Incidence data
Process and plot the incidence data. We will use a spline fitting to estimate te incidence from reported case counts, as case reporting is unreliable.
    
```{r incid, echo=FALSE, message=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.height=4}

## Get case count data (from JHU CSSE's github)
pull_JHUCSSE_github_data() # Pull and save data from github

# Compile the case data
jhucsse <- read_JHUCSSE_cases(last_time = Sys.time(), append_wiki=TRUE)

# Estimate incidence using spline fits.
incid_data <- est_daily_incidence_corrected(jhucsse, 
                                  ISOdate(2019,12,1),
                                  ISOdate(2020,02,29))

# ~ Incidence Data
incid_data <- incid_data %>% rename(source=Province_State, cases_incid=Incidence) %>% 
  mutate(source = as.character(source)) %>%
  mutate(source = ifelse(source=="Ningxia Hui", "Ningxia", source), t = as.Date(Date)) %>% 
  filter(source == "Hubei") %>%
  #filter(China_source==TRUE) %>% 
  as.data.frame()


## Plot current confirmed cases in China
conf_cases <- jhucsse %>% 
  filter(Country_Region == "Mainland China" | Province_State %in% c("Hong Kong", "Macau", "Taiwan")) %>%
  mutate(t = as.Date(Update)) %>% arrange(Province_State, Country_Region, Update) %>%
  group_by(Country_Region, Province_State) %>% mutate(Incidence = diff(c(0, Confirmed), na.rm=TRUE)) %>% ungroup() %>%
  group_by(Country_Region, Province_State, t) %>% summarise(Incidence = sum(Incidence, na.rm = TRUE))

conf_cases_orig <- conf_cases
conf_cases <- conf_cases %>% filter(t >= as.Date("2020-01-15"))
t_values <- as.character(sort(conf_cases$t))

p <- ggplot(data=conf_cases, aes(x=as.Date(t), y=Incidence, fill=Province_State)) + 
        geom_bar(position="stack", stat="identity", color="black") +
        ylab("Confirmed nCoV cases (n)") +
        theme(axis.line = element_line(colour = "black"),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
              panel.border = element_blank(), panel.background=element_blank(),
              axis.text.y = element_text(size=9), 
              axis.text.x = element_text(size=9, angle=45, hjust = 1),
              axis.title.x = element_blank(), legend.title=element_blank(), 
              legend.text=element_text(size=7), legend.key.size=unit(6, "pt"),
              #legend.margin=margin(0,0,0,0), legend.box.margin=margin(20,0,-20,-20),
              legend.background = element_blank(), legend.box.background = element_blank(),
              plot.title = element_text(size=8, face="bold", hjust = 0.025),
              plot.margin = unit(c(0.5,.25,0.25,0.25), "cm")) +
        guides(fill=guide_legend(ncol=1))
plot(p)


# Combine and save the data for use elsewhere
case_dat <- full_join(conf_cases_orig, 
                      incid_data %>% rename(est_incid=cases_incid, Province_State=source) %>% select(-Date))
write_csv(case_dat, "data/case_data.csv")

```

These are the reported case counts by date of confirmation. These are currently dominated by cases in Hubei.    
    

```{r incid_fits, echo=FALSE, message=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.height=4}
## Plot incidence fits
plot_incidence_ests_report(conf_cases=jhucsse, 
                           incid_ests=incid_data %>% rename(Incidence = cases_incid, Province_State=source),
                           locations="Hubei") +
  ggtitle("Hubei Corrected Incidence Estimates")
```
We have corrected for the large spike of cases on 13-14 February and smoothed over some of the heterogeneity that comes from reporting. These incidence estimates will be used in the importation model.



    



## Reported Importation data    
 *** TO BE COMPLETED ***

```{r reported_cases, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE, fig.height=4}

ca_cases <- jhucsse %>% filter(Province_State=="California")



#These get cleaned in `source("R/ncov_incidence_data_processing.R")`.
# # Reported from CDC
# shen_cases <- read_csv("data/shenzhen_data/shenzhen_case_counts.csv")
# shen_cases <- shen_cases %>% mutate(cum_cases = cumsum(count))
# # From Linelists
# ll_data <- read_csv("data/linelist_current.csv")
# shen_rows <- apply(ll_data, 1, FUN=function(x) sum(grepl("shenzhen", x, ignore.case = TRUE)))>0
# ll_data_shenzhen <- ll_data[shen_rows, ]
# shen_data_aggr <- ll_data_shenzhen %>% count(date_confirmation)
# rm(ll_data, ll_data_shenzhen, shen_rows)
# 
# shen_counts <- full_join(shen_cases %>% rename(count_CDC = count),
#                          shen_data_aggr %>% rename(count_ll = n, date=date_confirmation),
#                          by=c("date"="date"))
# shen_counts[is.na(shen_counts)] <- 0
# 
# 
# # Plot the epi curve of these
# p_incid_shen <- ggplot(shen_counts %>% mutate(label1 = "CDC counts", label2 = "Linelist counts"), 
#                      aes(x=date, y=count_CDC, color=label1, group=label1)) +
#                   geom_bar(stat="identity", fill="darkblue") +
#                   geom_point(aes(x=date,y=count_ll, shape=label2), color="maroon", size=2) +
#                   scale_color_manual(values=c(NA, "maroon")) +
#                   ylab("Reported Cases") + ggtitle("Shenzhen Reported nCoV Cases") + 
#                   xlab(NULL) +
#                   theme_classic() +
#                   theme(legend.position = c(0.05, 1), legend.justification = c(0, 1),
#                         legend.background = element_blank(),
#                         legend.title = element_blank())
#                 
# 
# # Plot cumulative cases in Shenzhen
# # Get cumulative case counts in each
# shen_counts <- shen_counts %>% arrange(date) %>% mutate(cum_CDC = cumsum(count_CDC), cum_ll = cumsum(count_ll))
# 
# p_cum_shen <- ggplot(shen_counts %>% mutate(label1 = "CDC cumulative", label2 = "Linelist cumulative"), 
#        aes(x=date, y=cum_CDC, color=label1, group=label1)) +
#     geom_bar(stat="identity", fill="darkblue") +
#     geom_point(aes(x=date,y=cum_ll, shape=label2), color="maroon", size=2) +
#     scale_color_manual(values=c(NA, "maroon")) +
#     ylab("Cumulative Reported Cases") + ggtitle("Shenzhen Cumulative Reported nCoV Cases") + xlab(NULL) +
#     theme_classic() +
#     theme(legend.position = c(0.05, 1), legend.justification = c(0, 1),
#           legend.background = element_blank(),
#           legend.title = element_blank())
# 
# p1 <- ggplot_gtable(ggplot_build(p_incid_shen))
# p2 <- ggplot_gtable(ggplot_build(p_cum_shen))
# maxWidth = grid::unit.pmax(p1$widths[2:5], p2$widths[2:5])
# p1$widths[2:5] <- as.list(maxWidth)
# p2$widths[2:5] <- as.list(maxWidth)
# gridExtra::grid.arrange(p1, p2, nrow=2)
# 

```

  

## Travel Data    

```{r travel, echo=FALSE, message=FALSE, eval=TRUE, fig.height=5}

source("R/setup_travel_data.R")
travel_data_monthly <- read_csv("data/wuhan_us_travel_monthly.csv")
travel_data_monthly <- travel_data_monthly %>% mutate(source="Hubei")
travel_data_daily <- make_daily_travel(travel_data=travel_data_monthly, travel_dispersion = 3)

# Airport Destinations
unique(travel_data_monthly$destination)

# Hubei Travel shutdown
hubei_shutdown <- "2020-01-25" # it might have been Jan 23, but we will give it 2 days for people already departed.

```

Travel data are currently provided by the U.S. CDC through from OAG. These are monthly passenger volumes of complete iterneraries (i.e., airport of departure to final destination), which we then do some sampling with in the model to distribute volume to individual days.

We will update this with travel forecasts eventually.
    

        
## Population Data

```{r pop, echo=FALSE, message=FALSE, eval=TRUE, warning=FALSE, message=FALSE}
source("R/setup_pop_data.R")
pop_data_file   <- file.path("data","pop_data.csv")
pop_data <- readr::read_csv(pop_data_file) %>% 
  rename(source = location, population=pop) %>% as.data.frame()

```
Population data are data for each province or country where transmission is currently occurring and from where importations could occur.
    
        
## Merge Input Data
Merge all of the input data into a single data.frame for inputting into the model
```{r, echo=FALSE, message=FALSE, eval=TRUE, warning=FALSE, message=FALSE}

## Incidence data
#  - Shift incid_data dates to align with incubation period
if (exists("shift_incid_days")){
  incid_data_preshift <- incid_data
  incid_data <- incid_data %>% mutate(t = as.Date(t) + shift_incid_days)
}

## Travel data
#  - Shift travel data 1 year forward to use it for 2019-2020
travel_data_monthly <- travel_data_monthly %>% mutate(t_year = t_year + 1)
#  - Stop travel after Jan 27 until May (crude)
travel_data_monthly <- travel_data_monthly %>% mutate(travelers = ifelse(t_year==2020 & t_month>=2 & t_month<=4, 0, travelers))
#  - Get daily for merging purposes
travel_data <- make_daily_travel(travel_data_monthly)
#  - Change source
travel_data <- travel_data %>% mutate(source="Hubei")

## Population data
#  >> nothing to do <<


# ~ Merge all data ----------------------------------------------------------

# make sure the location names match
source("R/match_names_func.R")

provinces_ <- as.character(pop_data$source)
travel_sources_ <- as.character(travel_data$source)
travel_provs <- sapply(travel_sources_, match_names,
                       names_b=provinces_,
                       return_match_scores=FALSE)
travel_data <- travel_data %>%
  mutate(source_orig = source) %>%
  mutate(source = travel_provs) %>%
  rowwise() %>% mutate(source = ifelse(is.na(source), source_orig, source))


incid_sources_ <- as.character(incid_data$source)
incid_provs <- sapply(incid_sources_, match_names,
                      names_b=provinces_,
                      return_match_scores=FALSE)
incid_data <- incid_data %>%
  mutate(source_orig = source) %>%
  mutate(source = incid_provs) %>% rowwise() %>% mutate(source = ifelse(is.na(source), source_orig, source))
incid_data <- incid_data %>% mutate(source = ifelse(source=="Inner Mongolia", "Nei Mongol", source))



# merge data (delimit it by travel data)
pop_data <- pop_data %>% mutate(source = as.character(source))
travel_data <- travel_data %>% mutate(source = as.character(source))
incid_data <- incid_data %>% mutate(source = as.character(source))

input_data <- full_join(right_join(pop_data, 
                                   travel_data %>% select(-source_orig), by=c("source")), 
                        incid_data %>% select(-source_orig), by=c("source"="source", "t"="t"))

start_date <- min((incid_data %>% filter(cases_incid>0))$t)

# filter data by time and location
input_data <- input_data %>%
  #filter(t > as.Date("2019-12-31")) %>% 
  filter(t >= as.Date(start_date)) %>% 
  mutate(cases_incid=ifelse(is.na(cases_incid), 0, cases_incid),
         epiweek = lubridate::epiweek(t))

# Make all negatives 0
input_data$travelers[input_data$travelers<0] <- 0


# SUMMARIZE DATA ----------------------------------------------------------
summ_dat <- input_data %>% group_by(destination, t) %>% summarise(travel_sum=sum(travelers, na.rm = TRUE),
                                                                  cases_incid_sum=sum(cases_incid, na.rm = TRUE))

```


    

# MODEL

Here we set up anything else for the model and running the simulations.    
    


### Model Setup

```{r modelsetup, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
#..........................................................................
# PARAMETERS -------------------------------------------------------------

# ~ delta (days per time period) -----------------------------------------
delta <- 1

# Add time unit to input data
input_data$days_per_t <- delta

#..........................................................................
# PARAMETER SAMPLING ------------------------------------------------------

# Mean D -- This is a combination of incubation period, time to hospitalization, and time to recovery
meanD <- round(
  exp(rnorm(n_sim, mean = incub_mean_log, sd = incub_sd_log)) +
    p_report_source[1]*rgamma(n_sim, shape=inf_period_hosp_shape, scale=inf_period_hosp_scale) +
    (1-p_report_source[1])*MCMCglmm::rtnorm(n_sim, inf_period_nohosp_mean, inf_period_nohosp_sd, lower=0))


# For first pass, reporting rate is just Hubei/not Hubei
input_data <- input_data %>% mutate(p_report_source = ifelse(source=="Hubei", p_report_source[1], p_report_source[2]))


# Sample the components of meanD -- will apply the p_report_source to these
meanD_mat_ <- cbind(
  exp(rnorm(n_sim, mean = incub_mean_log, sd = incub_sd_log)),
  rgamma(n_sim, shape=inf_period_hosp_shape, scale=inf_period_hosp_scale),
  MCMCglmm::rtnorm(n_sim, inf_period_nohosp_mean, inf_period_nohosp_sd, lower=0))


# Apply p_report_source by location and time to get the meanD matrix, where each simulation run has a pre-sampled set of D for each time/location combination
meanD_mat <- meanD_mat_[,1] + 
  meanD_mat_[,2] %*% matrix(input_data$p_report_source, nrow=1) + 
  meanD_mat_[,3] %*% matrix((1-input_data$p_report_source), nrow=1)

#hist(meanD, breaks=length(unique(meanD))-1)

par(mfrow=c(2,2))
hist(meanD_mat, breaks=length(unique(meanD))-1)
rm(meanD_mat_)


# ~ Time to detect importations -------------------------------------------
# -- If we assume people generally depart at some point during their incubation period, 
#     or very early in the symptomatic phase, 
#     we can generate a distribution of time from travel to detection.
# -- because we are only worried about those who are detected, we can ignore time to recover

time_inftodetect <- exp(rnorm(10000, mean = incub_mean_log, sd = incub_sd_log)) + 
  rgamma(10000, shape=inf_period_hosp_shape, scale=inf_period_hosp_scale)
hist(time_inftodetect, breaks=100)

# We assume people can and do travel during their incubation period and 
#  during that period during which symptoms are still minor. 
#  There are reports of travelers taking fever-reducers and a portion dont show fever
# We assume this is uniform
time_inftotravel <- sapply(time_inftodetect, runif, n=1, min=0)
hist(time_inftotravel, breaks=100)

time_traveltodetect <- time_inftodetect - time_inftotravel
hist(time_traveltodetect, breaks=100)
par(mfrow=c(1,1))


# ~ Travel reductions -----------------------------------------------------
t_red <- rep(1.5, n_sim)

# ~ Destination reporting rate --------------------------------------------
u_destination <- rep(1, n_sim)

# ~ Origin reporting rate -------------------------------------------------
u_origin <- matrix(rep(input_data$p_report_source, n_sim), nrow=n_sim, byrow = TRUE)


# Restrict forecast dates
input_data <- input_data %>% filter(t<as.Date(end_date))

# save final input data
readr::write_csv(input_data, file.path("data", project_name, 
                                       sprintf("input_data_%s_batch_v%s.RData", batch, version)))

```
    
The "meanD_mat" here is the distribution of time during which an infected indivudal could potentially travel from a source to a sink/destination. This distribution includes the time from infection to isolation/quarantine for detected cases (typically hospitalized/reported), travel restriction or a decision not to travel, or for cases with asymptomatic or very mild illness, until recovery. This value is drawn from a combination of the other distributions show here.    
    



### Run the Model

```{r modelrun, echo=FALSE, eval=F, message=FALSE, warning=FALSE}
source("R/import_model_source.R")
print(paste0("Proportion Reported in the sources: ",p_report_source))

# ~ Run the simulation ----------------------------------------------------

t.start <- proc.time() # start timer to measure this
input_data <- readr::read_csv(file.path("data", project_name, 
                                       sprintf("input_data_%s_batch_v%s.RData", batch, version)))

importation_sim_beforeJan25 <- run_daily_import_model_timeloc_withdailyest(input_data, 
                                                               travel_data_monthly, travel_dispersion=3, hubei_shutdown,
                                                               n_sim=n_sim, allow_travel_variance=FALSE,
                                                               meanD_mat, t_red, u_origin, time_inftotravel, time_inftodetect,
                                                               project_name, batch, version, print_progress=FALSE)

# importation_sim <- run_daily_import_model_timeloc(input_data, n_sim=n_sim, allow_travel_variance=allow_travel_variance,
#                                                   meanD_mat, t_red, u_origin, time_inftotravel, time_inftodetect,
#                                                   project_name, batch, version, print_progress=FALSE)


# print time required
print(paste0('Simulation required ', round(as.list(proc.time() - t.start)$elapsed/60, 3), ' minutes'))


```

    
    
# RESULTS

### Analysis of Model Simulations     
Clean, aggregate, and produce summary stats for importation simulation results.

```{r model_res, echo=FALSE, eval=F, message=FALSE, warning=FALSE}

t.start <- proc.time() # start timer to measure this
source("R/importation_analysis.R")
source("R/importation_analysis_detection.R")

# print time required
print(paste0('Analysis required ', round(as.list(proc.time() - t.start)$elapsed/60, 3), ' minutes'))

```

    

## Figure 1. Heatmaps of Risk of Importation into US Airports.
    
```{r plot_heatmapsA, echo=FALSE, message=FALSE, warning=FALSE, fig.height=8}
# Requires: `R/ggheat_func_source.R` and `R/heatmaps_exportation.R`    
# source("R/heatmaps_importation.R")

source("R/ggheat_func_source.R")
t_limits <- as.Date(c("2020-01-01","2020-02-15"))

# LOAD SIMULATED DATA ---------------------------------------------------------------
# dest by time, single destination 
import_results_desttime <- read_csv(file.path("results",project_name,sprintf("import_results_desttime_v%s.csv", version)))
import_results_desttime$t <- as.Date(import_results_desttime$t)
t_values <- sort(unique(import_results_desttime$t))
import_results_desttime <- import_results_desttime %>% 
    mutate(t = factor(as.character(t))) %>% mutate(t_num = as.integer(t))

# Subset to 20 locations with highest risk
cum_risk <- (import_results_desttime %>% group_by(destination) %>% summarise(cum_imports = sum(import_mean)) %>% 
  arrange(desc(cum_imports)))[1:25,]
import_results_desttime_top25 <- import_results_desttime %>% filter(destination %in% cum_risk$destination)

data <- import_results_desttime_top25
coord_ratio <- length(unique(data$destination)) / (length(unique(data$t))) /.1

# PLOTS -------------------------------------------------------------------
# RR importATION HEATMAP
summary(data$RR_mean)
quantile(data$RR_mean, probs=seq(0,1,.1), na.rm=TRUE)
zcuts_ <- c(0,.01,.2,.5,.8,1.25,2,10,20,50,100,200,500, ceiling(max(data$RR_mean, na.rm=TRUE)))
p_rr <- ggheat_import(data=data %>% select(t, destination, value=RR_mean) %>% 
                       rowwise %>% filter(as.Date(t) >= as.Date(t_limits[1]) &
                                            as.Date(t) <= as.Date(t_limits[2])),
                       zCuts=zcuts_,
                       x.size=8, y.size=8, 
                       title='Daily RR\nCase\nimported\ninto California', 
                       labCol='t', na.value="grey75",
                       aspect_ratio = coord_ratio, t.skip=3)
ggsave(file.path("figures",project_name,sprintf("heatmap_RR_importation_v%s.png", version)), plot=p_rr, width = 4, height = 8, dpi=600)


# PROB importATION HEATMAP
summary(data$prob_any_import)
quantile(data$prob_any_import, probs=seq(0,1,.1), na.rm=TRUE)
p_prob <- ggheat_import(data=data %>% select(t, destination, value=prob_any_import) %>%
                        rowwise %>% filter(as.Date(t) >= as.Date(t_limits[1]) & 
                                             as.Date(t) <= as.Date(t_limits[2])), 
                        zCuts=seq(0,1,.1), x.size=8, y.size=8, 
                        title='Daily\nProbability\nCase\nimported\ninto California', 
                        labCol='t', na.value="grey85", pal_colors=c("lightgoldenrod1","darkorange1","darkred"),
                        aspect_ratio = coord_ratio, t.skip=3)
ggsave(file.path("figures",project_name,sprintf("heatmap_PROB_importation_v%s.png", version)),plot=p_prob, width = 4, height = 8, dpi=600)


# Mean Number importation Heatmap
summary(data$import_mean)
quantile(data$import_mean, probs=seq(0,1,.1), na.rm=TRUE)
max_val_ <-  max(data$import_mean, na.rm=TRUE)
max_val_ <- ifelse(max_val_>=10, ceiling(max_val_/10)*10, ceiling(max_val_))        
        
if(max_val_>10) {  zcuts_ <- c(0, .2, .5, 1, 3, 5, seq(10, max_val_, 5))
} else {           zcuts_ <- c(0, .2, .5, seq(1, max_val_, 2))  }

p_mean <- ggheat_import(data=data %>% select(t, destination, value=import_mean) %>% 
                       rowwise %>% filter(as.Date(t) >= as.Date(t_limits[1]) & as.Date(t) <= as.Date(t_limits[2])),
                   zCuts=zcuts_,
                   x.size=8, y.size=8, title='Mean\nCases\nimported\ninto California', 
                   labCol='t', na.value="grey75", pal_colors=c("seashell","magenta4"),
                   aspect_ratio = coord_ratio, t.skip=3)
ggsave(file.path("figures",project_name,sprintf("heatmap_MEANNUMBER_importation_v%s.png", version)), 
       plot=p_mean, width=4, height=8, dpi=600)
rm(max_val_, zcuts_)


# Plot the heatmaps
plot(p_rr)

plot(p_prob)

# plot(p_mean)

# gridExtra::grid.arrange(p_rr, p_prob, p_mean, 
#                         layout_matrix=rbind(c(1,1,1,1), c(1,1,1,1), c(1,1,1,1), c(1,1,1,1),
#                                             c(2,2,3,3), c(2,2,3,3), c(2,2,3,3)))
```
We can see very clearly that the majority of risk coming from Hubei was into LAX, SFO, and JFK, with significant risk also into SEA, ORD, BOS, EWR, and HNL. This risk ends when flight restrictions are put into place. However, this analysis only includes flights from Hubei, so there still is risk from other locations in China.

    
    

## Figure 2. Estimated Importations into the US, total.

```{r plot_importsA, echo=FALSE, message=FALSE, warning=FALSE, fig.height=6}
# plotting functions and data loading
source("R/plot_importation_estimates.R")
# Date limits of plots
t_limits <- as.Date(c("2020-01-01","2020-02-15"))


# Daily importations, Overall (all of the US)
p_total <- plot_imports(data=import_results_desttime_overall, region_ = "All", t_limits=t_limits, 
                       y.size = 9, x.size = 9, leg.text.size = 12, leg.title.size = 14,
                       rep_col = "indianred2", 
                       est_col = "blue3", 
                       est_ribbon_col = "blue3", 
                       est_ribbon_alpha=0.25,
                       plot_legend=TRUE)
# Barchart version
p_total_barchart <- plot_imports_barchart(data=import_results_desttime_overall, region_ = "All", t_limits=t_limits,
                        y.size = 9, x.size = 9, leg.text.size = 12, leg.title.size = 14,
                        rep_col = "indianred2",
                        est_col = "blue3",
                        plot_legend=TRUE)

# Cumulative importations, Overall (all of the US)
p_cum <- plot_cum_imports(data=import_results_desttime_overall_cum, region_ = "All", t_limits=t_limits, 
                          y.size = 9, x.size = 9, leg.text.size = 12, leg.title.size = 14,
                          rep_col = "indianred2", 
                          est_col = "blue3", 
                          est_ribbon_col = "blue3", 
                          est_ribbon_alpha=0.25,
                          plot_legend=TRUE)

# Stacked barchart of daily importations by source (Currenty only source is Hubei)
p_stackedsource_barchart <- plot_imports_stackedsource(data=import_results_sourcetime, t_limits=t_limits, 
                                          y.size = 8, x.size = 8, leg.text.size = 6, leg.title.size = 8,
                                          rep_col = "indianred2", 
                                          est_col = "blue3")

# Stacked barchart of daily importations by destination (US Airports)
p_stackeddest_barchart <- plot_imports_stackeddest(data=import_results_desttime, t_limits=t_limits, 
                                                   y.size = 8, x.size = 8, leg.text.size = 6, leg.title.size = 8,
                                                   rep_col = "indianred2", 
                                                   est_col = "blue3")


gridExtra::grid.arrange(p_total, p_cum, nrow=2)

```

These figures show the total estimated number of importations into th US (top: daily, bottom: cumulative). Overall, we se that an average of 6 infections had been imported prior to the flight restrictions from Hubei, with a wide range of possibilities. These are infections being imported, not necessarily cases. 

Of note, because the airline travel data we are using are monthly aggregates, rather than daily, it is difficult to pinpoint actual risk on individual days. Right now we are imputing daily travel randomly from monthly numbers, which leads to our reliance on means and confidence bounds. However, the cumulative plot demonstrates the overall risk is somewhat in line with what we have seen. Going forward, particularly once we are out of the explosive period of the outbreak, these daily counts likely will not have as big of impact.
    
    
    
```{r plot_importsA2, echo=FALSE, message=FALSE, warning=FALSE, fig.height=4.25}

plot(p_stackeddest_barchart)

```
    
Here we see mean numbers of travelers are increasing with the increasing incidence in China. As the current analysis only includes travel from Wuhan (direct or indirect), the importation stops on January 25 (this may be a day or two off due to duration of flights, layovers, or enforcement of cancelations). These are mean importations, so because the actual numbers are so low, they are less than whole persons. As we see in the above plots, this is due to quite a bit of heterogeneity, and gives a general sense of the risk of importations.
           
           
## Figure 3. Detected Estimated Importations into US Airports from Hubei, China.

```{r plot_importsB, echo=FALSE, message=FALSE, warning=FALSE, fig.height=6}

t_limits <- as.Date(c("2020-01-01","2020-02-15"))
source("R/plot_importation_estimates_detection.R")

# Importation 
p_stackeddest_barchart <- plot_imports_stackeddest(data=import_results_desttime_detect, t_limits=t_limits, 
                                                   y.size = 8, x.size = 8, leg.text.size = 6, leg.title.size = 8,
                                                   rep_col = "indianred2", 
                                                   est_col = "blue3")

plot(p_stackeddest_barchart)


# Exportations by detection date
p_stackedsource_barchart <- plot_imports_stackedsource(data=import_results_sourcetime_detect, t_limits=t_limits, 
                                                   y.size = 8, x.size = 8, leg.text.size = 6, leg.title.size = 8,
                                                   rep_col = "indianred2", 
                                                   est_col = "blue3")

plot(p_stackedsource_barchart)

```

This figure represents te dates on which cases are likely to be (or to have been detected) if they were detected at all. We see these are delayed from the above figures, as most cases would be traveling before symptoms or during early phases of illness.

        
    
    
    
